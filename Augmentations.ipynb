{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334d8f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel\n",
    "import nltk\n",
    "import pytorch_lightning as pl\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27423f2c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084defc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (50876, 12) | Test shape: (50651, 11)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/HeadHunter_train.csv\")\n",
    "test = pd.read_csv(\"data/HeadHunter_test.csv\")\n",
    "sample_submission = pd.read_csv(\"data/HeadHunter_sample_submit.csv\")\n",
    "\n",
    "print(f\"Train shape: {train.shape} | Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c6d577",
   "metadata": {},
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9476fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import preprocessing, get_vocab, augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d281d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maksim/Desktop/hh_compete/data.py:78: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train[\"positive\"] = train[\"positive\"].str.replace(\"\\*{6,6}\", \"организация\")\n",
      "/home/maksim/Desktop/hh_compete/data.py:79: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train[\"negative\"] = train[\"negative\"].str.replace(\"\\*{6,6}\", \"организация\")\n",
      "/home/maksim/Desktop/hh_compete/data.py:80: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test[\"positive\"] = test[\"positive\"].str.replace(\"\\*{6,6}\", \"организация\")\n",
      "/home/maksim/Desktop/hh_compete/data.py:81: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test[\"negative\"] = test[\"negative\"].str.replace(\"\\*{6,6}\", \"организация\")\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing\n",
    "train, test = preprocessing(train.copy(), test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "train, val = train_test_split(train, test_size=0.1)\n",
    "\n",
    "print(f\"Train Size: {train.shape}, Val Size: {val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae58ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Augmentations\n",
    "train_positive_sentences, train_negative_sentences, train_meta, train_labels = augmentations(train)\n",
    "\n",
    "np.save(\"data/augmentations/train_positive_sentences\", np.asarray(train_positive_sentences))\n",
    "np.save(\"data/augmentations/train_negative_sentences\", np.asarray(train_negative_sentences))\n",
    "np.save(\"data/augmentations/train_meta\", np.asarray(train_meta))\n",
    "np.save(\"data/augmentations/train_labels\", np.asarray(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287043ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Val Augmentations\n",
    "val_positive_sentences, val_negative_sentences, val_meta, val_labels = augmentations(val, is_test=True)\n",
    "\n",
    "np.save(\"data/augmentations/val_positive_sentences\", np.asarray(val_positive_sentences))\n",
    "np.save(\"data/augmentations/val_negative_sentences\", np.asarray(val_negative_sentences))\n",
    "np.save(\"data/augmentations/val_meta\", np.asarray(val_meta))\n",
    "np.save(\"data/augmentations/val_labels\", np.asarray(val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test augmentations\n",
    "test_positive_sentences, test_negative_sentences, test_meta, _ = augmentations(test, is_test=True)\n",
    "\n",
    "np.save(\"data/augmentations/test_positive_sentences\", np.asarray(test_positive_sentences))\n",
    "np.save(\"data/augmentations/test_negative_sentences\", np.asarray(test_negative_sentences))\n",
    "np.save(\"data/augmentations/test_meta\", np.asarray(test_meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c663fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782c22afc4c84f68bfd00794c9b885df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maksim/Desktop/hh_compete/data.py:146: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.nn.Softmax()(positive_innapropriate.logits)\n",
      "/home/maksim/Desktop/hh_compete/data.py:153: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  torch.nn.Softmax()(negative_innapropriate.logits)\n"
     ]
    }
   ],
   "source": [
    "# Train Augmentations (as test)\n",
    "train_positive_sentences, train_negative_sentences, train_meta, train_labels = augmentations(train, is_test=True)\n",
    "\n",
    "np.save(\"data/augmentations/train2_positive_sentences\", np.asarray(train_positive_sentences))\n",
    "np.save(\"data/augmentations/train2_negative_sentences\", np.asarray(train_negative_sentences))\n",
    "np.save(\"data/augmentations/train2_meta\", np.asarray(train_meta))\n",
    "np.save(\"data/augmentations/train2_labels\", np.asarray(train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c4269f",
   "metadata": {},
   "source": [
    "## Save to batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e50ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cb747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train\n",
    "train_positive_sentences = np.load(\"data/augmentations/train_positive_sentences.npy\")\n",
    "train_negative_sentences = np.load(\"data/augmentations/train_negative_sentences.npy\")\n",
    "train_meta = np.load(\"data/augmentations/train_meta.npy\")\n",
    "train_labels = np.load(\"data/augmentations/train_labels.npy\")\n",
    "\n",
    "# load val\n",
    "val_positive_sentences = np.load(\"data/augmentations/val_positive_sentences.npy\")\n",
    "val_negative_sentences = np.load(\"data/augmentations/val_negative_sentences.npy\")\n",
    "val_meta = np.load(\"data/augmentations/val_meta.npy\")\n",
    "val_labels = np.load(\"data/augmentations/val_labels.npy\")\n",
    "\n",
    "# load test\n",
    "test_positive_sentences = np.load(\"data/augmentations/test_positive_sentences.npy\")\n",
    "test_negative_sentences = np.load(\"data/augmentations/test_negative_sentences.npy\")\n",
    "test_meta = np.load(\"data/augmentations/test_meta.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8703a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train\n",
    "for i in tqdm(range(len(train_positive_sentences))):\n",
    "    batch = np.array([train_positive_sentences[i], train_negative_sentences[i], list(train_meta[i]),\n",
    "                  list(train_labels[i])], dtype=\"object\")\n",
    "    np.save(f\"data/augmentations/train/train_{i}\", batch)\n",
    "    \n",
    "# save val\n",
    "for i in tqdm(range(len(val_positive_sentences))):\n",
    "    batch = np.array([val_positive_sentences[i], val_negative_sentences[i], list(val_meta[i]),\n",
    "                  list(val_labels[i])], dtype=\"object\")\n",
    "    np.save(f\"data/augmentations/val/val_{i}\", batch)\n",
    "    \n",
    "# save test\n",
    "for i in tqdm(range(len(test_positive_sentences))):\n",
    "    batch = np.array([test_positive_sentences[i], test_negative_sentences[i], list(test_meta[i])], dtype=\"object\")\n",
    "    np.save(f\"data/augmentations/test/test_{i}\", batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "686e5421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3421ea77a6114a308f29f3aed0e62a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50876 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load train\n",
    "train_positive_sentences = np.load(\"data/augmentations/train2_positive_sentences.npy\")\n",
    "train_negative_sentences = np.load(\"data/augmentations/train2_negative_sentences.npy\")\n",
    "train_meta = np.load(\"data/augmentations/train2_meta.npy\")\n",
    "train_labels = np.load(\"data/augmentations/train2_labels.npy\")\n",
    "\n",
    "# save train\n",
    "for i in tqdm(range(len(train_positive_sentences))):\n",
    "    batch = np.array([train_positive_sentences[i], train_negative_sentences[i], list(train_meta[i]),\n",
    "                  list(train_labels[i])], dtype=\"object\")\n",
    "    np.save(f\"data/augmentations/train2/train_{i}\", batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef9ac3",
   "metadata": {},
   "source": [
    "## Pseudo Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "311b58e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LSTMModel, Model, CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb321964",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_size = 112\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer_bert = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "tokenizer_lstm = nltk.RegexpTokenizer(r\"[а-я]+|<unk>|<pad>\")\n",
    "\n",
    "# load test and sort\n",
    "test_data = glob(\"data/augmentations/test/*.npy\")\n",
    "\n",
    "# data\n",
    "dataset_test = CustomDataset(test_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                              train_mode=False, model_type=\"lstm\")\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "875f28c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maksim/miniconda3/envs/hh_compete/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5877457997686522 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/maksim/miniconda3/envs/hh_compete/lib/python3.9/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b92eea50e5b433eb28ac87ec8ba7a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "model = LSTMModel.load_from_checkpoint(\"data/models/Final_Model_lstm.ckpt\")\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "# preds\n",
    "preds = trainer.predict(model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55ef00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preds2Classes\n",
    "const = 0.2\n",
    "thresholds = [const]\n",
    "y_pred = []\n",
    "count_zero = 0\n",
    "\n",
    "for pred in preds:\n",
    "    pred = (pred.numpy() > thresholds).astype(int).tolist()\n",
    "    y_pred.extend(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "480e80b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save pseudo labels\n",
    "for idx, data_path in enumerate(test_data):\n",
    "    pseudo_test = np.load(data_path, allow_pickle=True).tolist()\n",
    "    pseudo_test.append(y_pred[idx])\n",
    "    pseudo_test = np.array(pseudo_test, dtype=\"object\")    \n",
    "    np.save(f\"data/augmentations/test_pseudo/test_{idx}\", pseudo_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9cc799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e73f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8cc060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba72940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b2c383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9ce73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab70deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
