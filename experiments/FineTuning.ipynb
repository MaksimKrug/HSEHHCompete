{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ada90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.functional as F\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b467af8",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "043478da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c734cb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 118631, Val: 5088, Test: 50651\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer_bert = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "tokenizer_lstm = nltk.RegexpTokenizer(r\"[а-я]+|<unk>|<pad>\")\n",
    "\n",
    "# Load data\n",
    "train_data = glob(\"data/augmentations/train/*.npy\")\n",
    "val_data = glob(\"data/augmentations/val/*.npy\")\n",
    "test_data = glob(\"data/augmentations/test/*.npy\")\n",
    "test_pseudo = glob(\"data/augmentations/test_pseudo/*.npy\")\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c881a49",
   "metadata": {},
   "source": [
    "## Finetune LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c16b3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import init_RUBert, LSTMModel\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "231840af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_size = 112\n",
    "batch_size = 128\n",
    "\n",
    "# data\n",
    "dataset_train = CustomDataset(train_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                              train_mode=True, model_type=\"lstm\")\n",
    "dataset_val = CustomDataset(val_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                            train_mode=True, model_type=\"lstm\")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab66899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial):\n",
    "\n",
    "    # params\n",
    "    lr = trial.suggest_float(\"lr\", 2e-6, 2e-4)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-1)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 2, 256)\n",
    "    bidirectional = trial.suggest_categorical(\"bidirectional\", [True, False])\n",
    "    dropout_lstm = trial.suggest_float(\"dropout_lstm\", 0.0, 0.6)\n",
    "    dropout_linear = trial.suggest_float(\"dropout_linear\", 0.0, 0.6)\n",
    "    linear1_meta = trial.suggest_int(\"linear1_meta\", 32, 1024)\n",
    "    linear2_size = trial.suggest_int(\"linear2_size\", 32, 1024)\n",
    "\n",
    "    \n",
    "    params = {\"lr\": lr, \"weight_decay\": weight_decay, \n",
    "              \"hidden_size\": hidden_size,  \"bidirectional\": bidirectional,\n",
    "              \"dropout_lstm\":dropout_lstm, \"dropout_linear\":dropout_linear,\n",
    "              \"linear1_meta\":linear1_meta, \"linear2_size\":linear2_size}\n",
    "    \n",
    "    # model\n",
    "    model = LSTMModel(**params)\n",
    "    \n",
    "    # model utils\n",
    "    lr_monitoring = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "    early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_f1\", min_delta=0.0001, patience=3,\n",
    "                                                                    verbose=False, mode=\"max\")\n",
    "    logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\", name=\"final_model\")\n",
    "    \n",
    "    # train\n",
    "    trainer = pl.Trainer(gpus=1, max_epochs=15, callbacks=[lr_monitoring, early_stop_callback],\n",
    "                         default_root_dir=\"data/\", weights_summary=None, num_sanity_val_steps=0)\n",
    "    trainer.logger.log_hyperparams(params)\n",
    "    trainer.fit(model, dataloader_train, dataloader_val)\n",
    "    \n",
    "    return trainer.callback_metrics[\"val_f1\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "685f1018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100, timeout=6*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "792571f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.00019966166384916635,\n",
       " 'weight_decay': 0.021622317536040474,\n",
       " 'hidden_size': 207,\n",
       " 'bidirectional': True,\n",
       " 'dropout_lstm': 0.5877457997686522,\n",
       " 'dropout_linear': 0.2027970994869876,\n",
       " 'linear1_meta': 325,\n",
       " 'linear2_size': 739}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3702704",
   "metadata": {},
   "source": [
    "## Finetune LSTM Pseudo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "161d8384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import init_RUBert, LSTMModel\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "580ceb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_size = 112\n",
    "batch_size = 128\n",
    "\n",
    "# data\n",
    "dataset_train = CustomDataset(train_data+test_pseudo, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                              train_mode=True, model_type=\"lstm\")\n",
    "dataset_val = CustomDataset(val_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                            train_mode=True, model_type=\"lstm\")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "594f16ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in dataloader_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e8b4ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial):\n",
    "\n",
    "    # params\n",
    "    lr = trial.suggest_float(\"lr\", 2e-5, 2e-3)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-3, 1e-1)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 124, 512)\n",
    "    bidirectional = trial.suggest_categorical(\"bidirectional\", [True, False])\n",
    "    dropout_lstm = trial.suggest_float(\"dropout_lstm\", 0.2, 0.6)\n",
    "    dropout_linear = trial.suggest_float(\"dropout_linear\", 0.2, 0.6)\n",
    "    linear1_meta = trial.suggest_int(\"linear1_meta\", 124, 1024)\n",
    "    linear2_size = trial.suggest_int(\"linear2_size\", 124, 1024)\n",
    "\n",
    "    \n",
    "    params = {\"lr\": lr, \"weight_decay\": weight_decay, \n",
    "              \"hidden_size\": hidden_size,  \"bidirectional\": bidirectional,\n",
    "              \"dropout_lstm\":dropout_lstm, \"dropout_linear\":dropout_linear,\n",
    "              \"linear1_meta\":linear1_meta, \"linear2_size\":linear2_size}\n",
    "    \n",
    "    # model\n",
    "    model = LSTMModel(**params)\n",
    "    \n",
    "    # model utils\n",
    "    lr_monitoring = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "    early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_f1\", min_delta=0.0001, patience=3,\n",
    "                                                                    verbose=False, mode=\"max\")\n",
    "    logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\", name=\"final_model\")\n",
    "    \n",
    "    # train\n",
    "    trainer = pl.Trainer(gpus=1, max_epochs=15, callbacks=[lr_monitoring, early_stop_callback],\n",
    "                         default_root_dir=\"data/\", weights_summary=None, num_sanity_val_steps=0)\n",
    "    trainer.logger.log_hyperparams(params)\n",
    "    trainer.fit(model, dataloader_train, dataloader_val)\n",
    "    \n",
    "    return trainer.callback_metrics[\"val_f1\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7352a3fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=100, timeout=6*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3020fff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0007465276400229775,\n",
       " 'weight_decay': 0.06902483087263139,\n",
       " 'hidden_size': 394,\n",
       " 'bidirectional': True,\n",
       " 'dropout_lstm': 0.22293407982191252,\n",
       " 'dropout_linear': 0.235525995182581,\n",
       " 'linear1_meta': 849,\n",
       " 'linear2_size': 585}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d78a68d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521eb43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f31519eb",
   "metadata": {},
   "source": [
    "## Finetune threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0272aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CustomDataset\n",
    "from model import init_RUBert, LSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681c3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer_bert = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "tokenizer_lstm = nltk.RegexpTokenizer(r\"[а-я]+|<unk>|<pad>\")\n",
    "\n",
    "# Load data\n",
    "val_data = glob(\"data/augmentations/val/*.npy\")\n",
    "\n",
    "# Dataloader\n",
    "sent_size = 112\n",
    "batch_size = 128\n",
    "\n",
    "# data\n",
    "dataset_val = CustomDataset(val_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                            train_mode=True, model_type=\"lstm\")\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3893163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect labels\n",
    "y_true = []\n",
    "\n",
    "for x in dataloader_val:\n",
    "    y_true.extend(x[\"lstm\"][-1].numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7ad23b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528fc9f0ded04ea2b51997ddd7deeadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "model = LSTMModel.load_from_checkpoint(\"data/models/Final_Model_lstm.ckpt\")\n",
    "trainer = pl.Trainer(gpus=1)\n",
    "\n",
    "# preds\n",
    "preds = trainer.predict(model, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6c39fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "def objective(trial: optuna.trial.Trial):\n",
    "\n",
    "    # params\n",
    "    th1 = trial.suggest_float(\"th1\", 1e-6, 0.999)\n",
    "    th2 = trial.suggest_float(\"th2\", 1e-6, 0.999)\n",
    "    th3 = trial.suggest_float(\"th3\", 1e-6, 0.999)\n",
    "    th4 = trial.suggest_float(\"th4\", 1e-6, 0.999)\n",
    "    th5 = trial.suggest_float(\"th5\", 1e-6, 0.999)\n",
    "    th6 = trial.suggest_float(\"th6\", 1e-6, 0.999)\n",
    "    th7 = trial.suggest_float(\"th7\", 1e-6, 0.999)\n",
    "    th8 = trial.suggest_float(\"th8\", 1e-6, 0.999)\n",
    "    th9 = trial.suggest_float(\"th9\", 1e-6, 0.999)\n",
    "    \n",
    "    # get preds\n",
    "    y_pred = []\n",
    "    thresholds = [th1, th2, th3, th4, th5, th6, th7, th8, th9]\n",
    "\n",
    "    for pred in tqdm(preds):\n",
    "        pred = (pred.numpy() > thresholds).astype(int)\n",
    "        y_pred.extend(pred)\n",
    "    \n",
    "    score = f1_score(y_true, y_pred, average=\"samples\")\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ff6618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=200, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aa5f7b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'th1': 5.234075621788313e-05,\n",
       " 'th2': 0.5370042055765364,\n",
       " 'th3': 0.06012091756440158,\n",
       " 'th4': 0.8309953474038814,\n",
       " 'th5': 0.9066367495515553,\n",
       " 'th6': 0.5978267628247755,\n",
       " 'th7': 0.596118816153346,\n",
       " 'th8': 0.21056445096106394,\n",
       " 'th9': 1.0570610009207923e-05}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11463dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cdfd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adccc58a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659d648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
