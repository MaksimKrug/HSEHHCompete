{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "import nltk\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, BertTokenizer, BertModel\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.functional as F\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b467af8",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043478da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd66c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer_bert = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "tokenizer_lstm = nltk.RegexpTokenizer(r\"[а-я]+|<unk>|<pad>\")\n",
    "\n",
    "# Load data\n",
    "train_data = glob(\"../data/augmentations/train/*.npy\")\n",
    "val_data = glob(\"../data/augmentations/val/*.npy\")\n",
    "test_data = glob(\"../data/augmentations/test/*.npy\")\n",
    "test_pseudo = glob(\"../data/augmentations/test_pseudo/*.npy\")\n",
    "\n",
    "print(f\"Train: {len(train_data)}, Val: {len(val_data)}, Test: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c995a",
   "metadata": {},
   "source": [
    "## Train LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51924ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e08bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data = train_test_split(train_data + val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d914ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_size = 112\n",
    "batch_size = 128\n",
    "\n",
    "# data\n",
    "dataset_train = CustomDataset(train_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                              train_mode=True, model_type=\"lstm\")\n",
    "dataset_val = CustomDataset(val_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                            train_mode=True, model_type=\"lstm\")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5744aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'lr': 0.00019966166384916635, 'weight_decay': 0.021622317536040474,\n",
    "          'hidden_size': 207, 'bidirectional': True, 'dropout_lstm': 0.5877457997686522,\n",
    "          'dropout_linear': 0.2027970994869876, 'linear1_meta': 325, \n",
    "          'linear2_size': 739}\n",
    "\n",
    "    \n",
    "# model\n",
    "model = LSTMModel(**params)\n",
    "\n",
    "# model utils\n",
    "lr_monitoring = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\", mode = \"min\",\n",
    "                                          dirpath=\"data/models\", filename=\"lstm_checkpoint\")\n",
    "early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_f1\", min_delta=0.0001, patience=5,\n",
    "                                                                verbose=False, mode=\"max\")\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\", name=\"lstm_model\", version=\"optimized\")\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=15, logger=logger,\n",
    "                     callbacks=[lr_monitoring, early_stop_callback],\n",
    "                     default_root_dir=\"data/\", weights_summary=None, num_sanity_val_steps=0)\n",
    "trainer.fit(model, dataloader_train, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e78d105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "trainer.save_checkpoint(\"data/models/Final_Model_lstm.ckpt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8ef24",
   "metadata": {},
   "source": [
    "## Train LSTM Pseudo Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8074d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import LSTMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1dc07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data = train_test_split(train_data + val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bcd65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_size = 112\n",
    "batch_size = 128\n",
    "\n",
    "# data\n",
    "dataset_train = CustomDataset(train_data + test_pseudo, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                              train_mode=True, model_type=\"lstm\")\n",
    "dataset_val = CustomDataset(val_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                            train_mode=True, model_type=\"lstm\")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d26d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'lr': 0.0007465276400229775, 'weight_decay': 0.06902483087263139,\n",
    "          'hidden_size': 394, 'bidirectional': True, 'dropout_lstm': 0.22293407982191252,\n",
    "          'dropout_linear': 0.235525995182581, 'linear1_meta': 849, 'linear2_size': 585}\n",
    "\n",
    "    \n",
    "# model\n",
    "model = LSTMModel(**params)\n",
    "\n",
    "# model utils\n",
    "lr_monitoring = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\", mode = \"min\",\n",
    "                                          dirpath=\"data/models\", filename=\"lstm_checkpoint\")\n",
    "early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_f1\", min_delta=0.0001, patience=5,\n",
    "                                                                verbose=False, mode=\"max\")\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\", name=\"lstm_model\", version=\"pseudo\")\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=15, logger=logger,\n",
    "                     callbacks=[lr_monitoring, early_stop_callback],\n",
    "                     default_root_dir=\"data/\", weights_summary=None, num_sanity_val_steps=0)\n",
    "trainer.fit(model, dataloader_train, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c962be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "trainer.save_checkpoint(\"data/models/Final_Model_lstm_pseudo.ckpt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547160e4",
   "metadata": {},
   "source": [
    "## Train Model Not Retrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c24fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import init_RUBert, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e1ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_size = 112\n",
    "batch_size = 8\n",
    "\n",
    "# data\n",
    "dataset_train = CustomDataset(train_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                              train_mode=True, model_type=\"bert\")\n",
    "dataset_val = CustomDataset(val_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                            train_mode=True, model_type=\"bert\")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e00da3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "params = {\"lr\": 2e-5, \"weight_decay\": 1e-3,  \"is_train\": False, \"linear1_meta_size\": 512,\n",
    "          \"linear1_token_size\":512, \"linear2_size\":1024, \"dropout1_weight\":0.2, \"dropout2_weight\":0.3}\n",
    "model = Model(**params)\n",
    "\n",
    "# model utils\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\", mode = \"min\",\n",
    "                                          dirpath=\"data/models\", filename=\"final_model_checkpoint\")\n",
    "lr_monitoring = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_f1\", min_delta=0.00001,\n",
    "                                                                patience=5, verbose=True, mode=\"max\")\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\", name=\"final_model\", version=\"not_retrained\")\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=15, logger=logger, accumulate_grad_batches=16,\n",
    "                     callbacks=[lr_monitoring, checkpoint],\n",
    "                     default_root_dir=\"data/\", weights_summary=None, num_sanity_val_steps=0)\n",
    "trainer.fit(model, dataloader_train, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd7c120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "trainer.save_checkpoint(\"data/models/Final_Model_notretrained.ckpt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c3d4e",
   "metadata": {},
   "source": [
    "## Train Retrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618f2c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import init_RUBert, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_size = 112\n",
    "batch_size = 8\n",
    "\n",
    "# data\n",
    "dataset_train = CustomDataset(train_data+test_pseudo, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                              train_mode=True, model_type=\"bert\")\n",
    "dataset_val = CustomDataset(val_data, tokenizer_bert, tokenizer_lstm, sent_size=sent_size,\n",
    "                            train_mode=True, model_type=\"bert\")\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc260f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "params = {\"lr\": 2e-5, \"weight_decay\": 1e-3,  \"is_train\": True, \"linear1_meta_size\": 512,\n",
    "          \"linear1_token_size\":512, \"linear2_size\":1024, \"dropout1_weight\":0.2, \"dropout2_weight\":0.3}\n",
    "model = Model(**params)\n",
    "\n",
    "# model utils\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\", mode = \"min\",\n",
    "                                          dirpath=\"data/models\", filename=\"final_model_checkpoint\")\n",
    "lr_monitoring = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_f1\", min_delta=0.00001,\n",
    "                                                                patience=5, verbose=True, mode=\"max\")\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\", name=\"final_model\", version=\"retrained_pseudo\")\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=15, min_epochs=7, logger=logger, accumulate_grad_batches=16,\n",
    "                     callbacks=[lr_monitoring, checkpoint],\n",
    "                     default_root_dir=\"data/\", weights_summary=None)\n",
    "trainer.fit(model, dataloader_train, dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fed0218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "trainer.save_checkpoint(\"data/models/Final_Model_retrained_pseudo.ckpt\", weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1a938a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4e9642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e6d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6eae9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed4dc15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
