{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96bc774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import fasttext\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.functional as F\n",
    "from torch import nn\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42cf6f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings\n",
    "from navec import Navec\n",
    "path = \"data/navec_hudlit_v1_12B_500K_300d_100q.tar\"\n",
    "navec = Navec.load(path)\n",
    "\n",
    "# for synonyms\n",
    "# fasttext_model = fasttext.load_model(\"data/cc.ru.300.bin\")\n",
    "\n",
    "# stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7055a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# synonyms = model.get_nearest_neighbors(\"********\", k=10)\n",
    "# synonyms = [i[1] for i in synonyms]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85deb06a",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5202a749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (50876, 12) | Test shape: (50651, 11)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/HeadHunter_train.csv\")\n",
    "test = pd.read_csv(\"data/HeadHunter_test.csv\")\n",
    "sample_submission = pd.read_csv(\"data/HeadHunter_sample_submit.csv\")\n",
    "\n",
    "print(f\"Train shape: {train.shape} | Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57d52e2",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2da48f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENT_SIZE = 124 # q_95\n",
    "META_SIZE = 6\n",
    "METADATA_SIZE = 10\n",
    "VEC_SIZE = 300\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9144eb23",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89a2b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# NaNs preprocessing\n",
    "train.fillna(value={\"city\":\"<unk>\", \"position\":\"<unk>\", \"positive\":\"<unk>\", \"negative\":\"<unk>\"}, inplace=True)\n",
    "test.fillna(value={\"city\":\"<unk>\", \"position\":\"<unk>\", \"positive\":\"<unk>\", \"negative\":\"<unk>\"}, inplace=True) \n",
    "\n",
    "# lowercase\n",
    "train[[\"positive\", \"negative\"]] = train[[\"positive\", \"negative\"]].apply(lambda x: x.str.lower())\n",
    "test[[\"positive\", \"negative\"]] = test[[\"positive\", \"negative\"]].apply(lambda x: x.str.lower())\n",
    "\n",
    "# # One Hot\n",
    "# concat_temp = pd.concat((train, test))\n",
    "# metadata_columns = [\"salary_rating\", \"team_rating\", \"managment_rating\",\n",
    "#                     \"career_rating\", \"workplace_rating\", \"rest_recovery_rating\"]\n",
    "# concat_temp = pd.get_dummies(concat_temp, columns=metadata_columns)\n",
    "# dummies_columns = [i for i in concat_temp.columns if len([j for j in metadata_columns if j in i]) != 0]\n",
    "# train = concat_temp.loc[concat_temp[\"target\"].notna()]\n",
    "# test = concat_temp.loc[concat_temp[\"target\"].isna()]\n",
    "\n",
    "# standard scaler\n",
    "scaler = StandardScaler()\n",
    "scaler_columns = [\"salary_rating\", \"team_rating\", \"managment_rating\",\n",
    "                  \"career_rating\", \"workplace_rating\", \"rest_recovery_rating\"]\n",
    "train[scaler_columns] = scaler.fit_transform(train[scaler_columns])\n",
    "test[scaler_columns] = scaler.transform(test[scaler_columns])\n",
    "\n",
    "# target to single label\n",
    "train[\"preprocessed_target\"] = train[\"target\"].apply(lambda x: [1 if str(i) in x.split(\",\") else 0 for i in range(9)])\n",
    "\n",
    "# reset index\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abea132e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 s, sys: 24.2 ms, total: 6.02 s\n",
      "Wall time: 6.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# vocab\n",
    "tokenizer = nltk.RegexpTokenizer(r\"[а-я]+|<unk>|[a-z]+\")\n",
    "word2idx = {\"<pad>\":0, \"<unk>\":1}\n",
    "idx = 2\n",
    "\n",
    "# create vocab\n",
    "for text_column in [\"positive\", \"negative\"]:\n",
    "    text = train[text_column].values\n",
    "    tokens = [tokenizer.tokenize(sent) for sent in text]\n",
    "    for idx, sent in enumerate(tokens):        \n",
    "        for word in sent:\n",
    "            if word in stopwords:\n",
    "                continue\n",
    "            word_emb = navec.get(word)\n",
    "            if word not in word2idx and word_emb is not None:\n",
    "                word2idx[word] = idx\n",
    "                idx += 1\n",
    "    \n",
    "# idx2word\n",
    "idx2word = {j:i for j,i in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff3d322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (45788, 13), Val Shape: (5088, 13)\n"
     ]
    }
   ],
   "source": [
    "# split\n",
    "train, val = train_test_split(train, test_size=0.1, shuffle=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Train Shape: {train.shape}, Val Shape: {val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d267d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, sent_size, train_mode):\n",
    "        # utils\n",
    "        metadata_columns = [\"salary_rating\", \"team_rating\", \"managment_rating\",\n",
    "                            \"career_rating\", \"workplace_rating\", \"rest_recovery_rating\"]\n",
    "        # for one hot\n",
    "        metadata_columns = [i for i in df.columns if len([j for j in metadata_columns if j in i]) != 0]\n",
    "        self.tokenizer = nltk.RegexpTokenizer(r\"[а-я]+|<unk>|<pad>\")\n",
    "        \n",
    "        # utils\n",
    "        self.train_mode = train_mode\n",
    "        self.sent_size = sent_size\n",
    "        \n",
    "        # init features\n",
    "        self.positive = df[\"positive\"].values\n",
    "        self.negative = df[\"negative\"].values\n",
    "        self.cities = df[\"city\"].values\n",
    "        self.position = df[\"position\"].values\n",
    "        self.metadata = df[metadata_columns].values\n",
    "        if self.train_mode:\n",
    "            self.target = df[\"preprocessed_target\"].values\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.positive)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # get sent\n",
    "        positive, negative = self.positive[idx], self.negative[idx]\n",
    "#         tokens_city, tokens_position = self.cities[idx], self.position[idx]\n",
    "        metadata = self.metadata[idx]\n",
    "        \"\"\"\n",
    "        For text:\n",
    "\n",
    "        \"\"\"\n",
    "        # tokenization\n",
    "        tokens_positive = tokenizer.tokenize(positive)\n",
    "        tokens_negative = tokenizer.tokenize(negative)\n",
    "        # word2idx\n",
    "        tokens_positive = [word2idx[w] if w in word2idx else word2idx[\"<unk>\"] for w in tokens_positive]\n",
    "        tokens_negative = [word2idx[w] if w in word2idx else word2idx[\"<unk>\"] for w in tokens_negative]\n",
    "        # padding\n",
    "        tokens_positive = np.pad(tokens_positive[:self.sent_size],\n",
    "                                 pad_width=(max(0, self.sent_size - len(tokens_positive)), 0), \n",
    "                                 constant_values=(word2idx[\"<pad>\"], word2idx[\"<pad>\"]))\n",
    "        tokens_negative = np.pad(tokens_negative[:self.sent_size],\n",
    "                                 pad_width=(max(0, self.sent_size - len(tokens_negative)), 0), \n",
    "                                 constant_values=(word2idx[\"<pad>\"], word2idx[\"<pad>\"]))   \n",
    "        # stack tokens\n",
    "        tokens_positive = np.stack(tokens_positive)\n",
    "        tokens_negative = np.stack(tokens_negative)\n",
    "        # cnvert tokens 2 Long\n",
    "        tokens_positive = torch.LongTensor(tokens_positive)\n",
    "        tokens_negative = torch.LongTensor(tokens_negative)\n",
    "        \n",
    "        \"\"\"\n",
    "        For metadata:\n",
    "        1) len(positive)\n",
    "        2) len(negative)\n",
    "        3) percent <unk> in positive\n",
    "        4) percent <unk> in negative\n",
    "        \"\"\"\n",
    "        metadata = metadata.tolist()\n",
    "        metadata += [(tokens_positive != 0).sum().item() / self.sent_size]\n",
    "        metadata += [(tokens_negative != 0).sum().item() / self.sent_size]\n",
    "        metadata += [(tokens_positive != 1).sum().item() / self.sent_size]\n",
    "        metadata += [(tokens_negative != 1).sum().item() / self.sent_size]\n",
    "        \n",
    "        \"\"\"\n",
    "        For target\n",
    "        \"\"\"        \n",
    "        if self.train_mode:\n",
    "            target = self.target[idx]\n",
    "            return tokens_positive, tokens_negative, torch.FloatTensor(metadata), torch.FloatTensor(target)\n",
    "        else:\n",
    "            return tokens_positive, tokens_negative, torch.FloatTensor(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9ac34b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "dataset_train = CustomDataset(train, sent_size=112, train_mode=True)\n",
    "dataset_val = CustomDataset(val, sent_size=112, train_mode=True)\n",
    "dataset_test = CustomDataset(test, sent_size=112, train_mode=False)\n",
    "dataset_fulltrain = CustomDataset(pd.concat((train, val)), sent_size=112, train_mode=True)\n",
    "\n",
    "# create dataloaders\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_fulltrain = DataLoader(dataset_fulltrain, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4beaf981",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tokens_positive, tokens_negative,  metadata, target in dataloader_train:\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd3c82c",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a92b6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb weights\n",
    "vocab = list(word2idx.keys())\n",
    "emb_weights = np.zeros((len(vocab), VEC_SIZE))\n",
    "for idx, (word, word_idx) in enumerate(word2idx.items()):\n",
    "    emb_weights[idx] = navec.get(word)\n",
    "    assert navec.get(word) is not None\n",
    "\n",
    "def create_emb_layer(emb_weights, train_embed=False):\n",
    "    \"\"\"\n",
    "    Create embeddings\n",
    "    \"\"\"\n",
    "    num_embeddings, embedding_dim = emb_weights.shape\n",
    "    emb_layer = nn.Embedding.from_pretrained(torch.from_numpy(emb_weights))\n",
    "    emb_layer.weight.requires_grad = train_embed\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f2f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(WordAttention, self).__init__()\n",
    "\n",
    "        self.attention = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.context = nn.Linear(hidden_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out_attention = torch.nn.Tanh()(self.attention(x))\n",
    "        out_context = torch.nn.Softmax(dim=1)(self.context(out_attention))\n",
    "        out = (out_context * x).sum(1)\n",
    "        \n",
    "        return out_context.permute(0, 2, 1), out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a20da743",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(pl.LightningModule,):\n",
    "    def __init__(self, learning_rate=1e-3, weight_decay=1e-8, hidden_size=4, bidirectional=True, linear_size=512,\n",
    "                 dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        # save hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "        # utils\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bidirectional = bidirectional\n",
    "        self.linear_size = linear_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        # metrics\n",
    "        self.metric_accuracy = torchmetrics.Accuracy()\n",
    "        self.metric_f1 = torchmetrics.F1(num_classes=9, average=\"samples\")\n",
    "        # logs\n",
    "        self.train_accuracy_log, self.train_f1_log, self.train_loss_log = [], [], []\n",
    "        self.val_accuracy_log, self.val_f1_log, self.val_loss_log = [], [], []\n",
    "        \n",
    "        # model\n",
    "        self.emb_layer_positive, _, self.embedding_dim = create_emb_layer(emb_weights, train_embed=True)\n",
    "        self.emb_layer_negative, _, self.embedding_dim = create_emb_layer(emb_weights, train_embed=True)\n",
    "        \n",
    "        self.lstm_layer_positive = nn.LSTM(input_size=VEC_SIZE, hidden_size=self.hidden_size,\n",
    "                                           bidirectional=self.bidirectional, dropout=0.2,\n",
    "                                           batch_first=True)\n",
    "        self.lstm_layer_negative = nn.LSTM(input_size=VEC_SIZE, hidden_size=self.hidden_size,\n",
    "                                           bidirectional=self.bidirectional, dropout=0.2,\n",
    "                                           batch_first=True)\n",
    "        \n",
    "        self.attention_positive = WordAttention(hidden_size*(self.bidirectional+1))\n",
    "        self.attention_negative = WordAttention(hidden_size*(self.bidirectional+1))\n",
    "        \n",
    "        self.linear1_positive = nn.Linear(self.hidden_size*(self.bidirectional+1), self.linear_size)\n",
    "        self.linear1_negative = nn.Linear(self.hidden_size*(self.bidirectional+1), self.linear_size)\n",
    "        self.linear1_metadata = nn.Linear(METADATA_SIZE, self.linear_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(3*self.linear_size, 9) \n",
    "        \n",
    "        # extra utils\n",
    "        self.dropout = nn.Dropout(self.dropout_rate)\n",
    "        \n",
    "    def forward(self, tokens_positive, tokens_negative, metadata):        \n",
    "        # embeddings\n",
    "        emb_positive = self.emb_layer_positive(tokens_positive)\n",
    "        emb_negative = self.emb_layer_negative(tokens_negative)\n",
    "        \n",
    "        # dropout\n",
    "        emb_positive = self.dropout(emb_positive)\n",
    "        emb_negative = self.dropout(emb_negative)\n",
    "           \n",
    "        # lstm\n",
    "        lstm_out_positive, (h_n, c_n) = self.lstm_layer_positive(emb_positive.float())\n",
    "        lstm_out_negative, (h_n, c_n) = self.lstm_layer_negative(emb_negative.float())\n",
    "        \n",
    "        # attention\n",
    "        _, out_positive = self.attention_positive(lstm_out_positive)\n",
    "        _, out_negative = self.attention_negative(lstm_out_negative)\n",
    "        \n",
    "        # fc\n",
    "        x_positive = self.linear1_positive(out_positive)\n",
    "        x_negative = self.linear1_negative(out_negative)\n",
    "        x_metadata = self.linear1_metadata(metadata)\n",
    "        x = torch.cat((x_positive, x_negative, x_metadata), dim=1)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = torch.nn.Sigmoid()(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate,\n",
    "                                     weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=False)\n",
    "        #learning rate scheduler\n",
    "        return {\"optimizer\":optimizer,\n",
    "                \"lr_scheduler\" : {\"scheduler\" : scheduler, \"monitor\": \"val_f1\"}\n",
    "               }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        tokens_positive, tokens_negative, metadata, y = batch\n",
    "        out = self(tokens_positive, tokens_negative, metadata)\n",
    "        loss = torch.nn.BCELoss()(out, y)\n",
    "        accuracy = self.metric_accuracy(out, y.int())\n",
    "        f1 = self.metric_f1(out, y.int())\n",
    "        \n",
    "        # save logs\n",
    "        self.log(\"train_loss\", loss, prog_bar=True)\n",
    "        self.log(\"train_accuracy\", accuracy, prog_bar=True)\n",
    "        self.log(\"train_f1\", f1, prog_bar=True)\n",
    "\n",
    "        return {\"loss\": loss, \"accuracy\": accuracy, \"F1\":f1}\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        tokens_positive, tokens_negative, metadata, y = batch\n",
    "        out = self(tokens_positive, tokens_negative, metadata)        \n",
    "        loss = torch.nn.BCELoss()(out, y)\n",
    "        accuracy = self.metric_accuracy(out, y.int())\n",
    "        f1 = self.metric_f1(out, y.int())\n",
    "        \n",
    "        # save logs\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        self.log(\"val_accuracy\", accuracy, prog_bar=True)\n",
    "        self.log(\"val_f1\", f1, prog_bar=True)\n",
    "        self.log(\"hp_metric\", f1)\n",
    "\n",
    "        return {\"loss\": loss, \"accuracy\": accuracy, \"F1\":f1}\n",
    "        \n",
    "    def training_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        self.train_loss_log.append(np.mean([i[\"loss\"].item() for i in outs]))\n",
    "        self.train_accuracy_log.append(np.mean([i[\"accuracy\"].cpu() for i in outs]))\n",
    "        self.train_f1_log.append(np.mean([i[\"F1\"].cpu() for i in outs]))\n",
    "\n",
    "\n",
    "    def validation_epoch_end(self, outs):\n",
    "        # log epoch metric\n",
    "        self.val_loss_log.append(np.mean([i[\"loss\"].item() for i in outs]))\n",
    "        self.val_accuracy_log.append(np.mean([i[\"accuracy\"].cpu() for i in outs]))\n",
    "        self.val_f1_log.append(np.mean([i[\"F1\"].cpu() for i in outs]))\n",
    "        \n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        tokens_positive, tokens_negative, metadata = batch\n",
    "        out = self(tokens_positive, tokens_negative, metadata)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c1a26b",
   "metadata": {},
   "source": [
    "### Hypeopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acdc11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c157fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial):\n",
    "\n",
    "    # params\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-6, 1e-3)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-12, 1e-2)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 1, 64)\n",
    "    bidirectional = trial.suggest_categorical(\"bidirectional\", [True, False])\n",
    "    linear_size = trial.suggest_int(\"linear_size\", 112, 1024)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.0, 0.6)\n",
    "    sent_size = trial.suggest_int(\"sent_size\", 50, 150)\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 4, 256)    \n",
    "    \n",
    "    hyperparameters = {\"learning_rate\":learning_rate, \"weight_decay\":weight_decay,\n",
    "                       \"hidden_size\":hidden_size, \"bidirectional\":bidirectional,\n",
    "                       \"linear_size\":linear_size, \"dropout_rate\":dropout_rate}\n",
    "    \n",
    "    # data\n",
    "    dataset_train = CustomDataset(train, sent_size=sent_size, train_mode=True)\n",
    "    dataset_val = CustomDataset(val, sent_size=sent_size, train_mode=True)\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # model\n",
    "    lstm_model = LSTMModel(learning_rate, weight_decay, hidden_size, bidirectional, linear_size, dropout_rate)\n",
    "    checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\", mode = \"min\", dirpath=\"data/\", filename=\"bilstm\")\n",
    "    lr_monitoring = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "    early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_f1\", min_delta=0.00, patience=4, verbose=False, mode=\"max\")\n",
    "    logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\", name=\"lstm_attention\")\n",
    "    \n",
    "    # train\n",
    "    trainer = pl.Trainer(gpus=1, max_epochs=15, logger=logger, callbacks=[lr_monitoring, early_stop_callback],\n",
    "                         default_root_dir=\"data/\", auto_lr_find=True, weights_summary=None)\n",
    "    trainer.logger.log_hyperparams(hyperparameters)\n",
    "    trainer.fit(lstm_model, dataloader_train, dataloader_val)\n",
    "\n",
    "    return trainer.callback_metrics[\"val_f1\"].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dac8e4ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# study = optuna.create_study(direction=\"maximize\")\n",
    "# study.optimize(objective, n_trials=100, timeout=2*60*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "045ba5b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0002513194765987834,\n",
       " 'weight_decay': 0.00023611620695341944,\n",
       " 'hidden_size': 55,\n",
       " 'bidirectional': True,\n",
       " 'linear_size': 1012,\n",
       " 'dropout_rate': 0.5950975603765589,\n",
       " 'sent_size': 56,\n",
       " 'batch_size': 38}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c05d019",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63d0a56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                | Type          | Params\n",
      "-------------------------------------------------------\n",
      "0  | metric_accuracy     | Accuracy      | 0     \n",
      "1  | metric_f1           | F1            | 0     \n",
      "2  | emb_layer_positive  | Embedding     | 15.6 M\n",
      "3  | emb_layer_negative  | Embedding     | 15.6 M\n",
      "4  | lstm_layer_positive | LSTM          | 157 K \n",
      "5  | lstm_layer_negative | LSTM          | 157 K \n",
      "6  | attention_positive  | WordAttention | 12.3 K\n",
      "7  | attention_negative  | WordAttention | 12.3 K\n",
      "8  | linear1_positive    | Linear        | 112 K \n",
      "9  | linear1_negative    | Linear        | 112 K \n",
      "10 | linear1_metadata    | Linear        | 11.1 K\n",
      "11 | relu                | ReLU          | 0     \n",
      "12 | linear2             | Linear        | 27.3 K\n",
      "13 | dropout             | Dropout       | 0     \n",
      "-------------------------------------------------------\n",
      "31.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.8 M    Total params\n",
      "127.085   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db0f9336b804766b88e9f8015afae7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 16s, sys: 8.73 s, total: 7min 25s\n",
      "Wall time: 7min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# params\n",
    "best_params = {'learning_rate': 0.0002513194765987834, 'weight_decay': 0.00023611620695341944,\n",
    "               'hidden_size': 55, 'bidirectional': True, 'linear_size': 1012,\n",
    "               'dropout_rate': 0.5950975603765589}\n",
    "\n",
    "sent_size = 56\n",
    "batch_size = 38\n",
    "\n",
    "# data\n",
    "dataset_train = CustomDataset(train, sent_size=sent_size, train_mode=True)\n",
    "dataset_val = CustomDataset(val, sent_size=sent_size, train_mode=True)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# create model\n",
    "lstm_model = LSTMModel(**best_params) # learning_rate, weight_decay, hidden_size, bidirectional, linear_size, dropout_rate)\n",
    "checkpoint = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\", mode = \"min\", dirpath=\"data/\", filename=\"bilstm\")\n",
    "lr_monitoring = pl.callbacks.LearningRateMonitor(logging_interval=\"epoch\")\n",
    "early_stop_callback = pl.callbacks.early_stopping.EarlyStopping(monitor=\"val_f1\", min_delta=0.00, patience=3, verbose=False, mode=\"max\")\n",
    "logger = pl.loggers.TensorBoardLogger(save_dir=\"logs\", name=\"lstm_attention\")\n",
    "\n",
    "# train\n",
    "trainer = pl.Trainer(gpus=1, max_epochs=15, logger=logger, callbacks=[lr_monitoring, early_stop_callback],\n",
    "                     default_root_dir=\"data/\", auto_lr_find=True)\n",
    "trainer.fit(lstm_model, dataloader_train, dataloader_val)\n",
    "\n",
    "# save model\n",
    "trainer.save_checkpoint(\"data/models/BILstm_attention.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dcc21d",
   "metadata": {},
   "source": [
    "## Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "622e102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1e277e39a84d499d98799c833d01bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 1205it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 44s, sys: 314 ms, total: 2min 44s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = trainer.predict(lstm_model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6704a865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcff5610821248548c7eae8369f2ba3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50651 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4453e-04, 4.4036e-02, 6.7410e-10, 1.3379e-01, 6.6564e-05, 3.8361e-04,\n",
      "         4.5827e-04, 6.5299e-05, 1.3423e-01]])\n",
      "tensor([[3.7928e-04, 3.5203e-03, 9.6458e-10, 1.9976e-01, 3.5124e-05, 1.5491e-04,\n",
      "         2.6519e-02, 3.0001e-05, 1.3648e-01]])\n",
      "tensor([[1.4436e-03, 1.3448e-03, 1.7903e-08, 1.8679e-01, 3.6873e-05, 1.7914e-04,\n",
      "         2.2573e-04, 6.0680e-05, 9.0712e-02]])\n",
      "tensor([[1.8369e-01, 1.4236e-01, 1.3058e-05, 5.3578e-03, 2.3162e-03, 2.5184e-02,\n",
      "         1.0690e-02, 2.3393e-03, 1.3418e-01]])\n",
      "tensor([[2.4125e-04, 8.3625e-03, 2.5383e-09, 1.8364e-01, 5.6786e-05, 3.9037e-04,\n",
      "         3.7014e-04, 1.3091e-04, 1.2621e-01]])\n",
      "CPU times: user 2.2 s, sys: 19.9 ms, total: 2.22 s\n",
      "Wall time: 579 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# save test preds\n",
    "submit = []\n",
    "thresh1, thresh2, thresh3 = 0.2, 0.2, 0.2\n",
    "\n",
    "for pred in tqdm(preds):\n",
    "    pred_batch = torch.where((pred > thresh1)[0])[0].detach().tolist()\n",
    "    pred_batch = \",\".join([str(i) for i in pred_batch])\n",
    "    if pred_batch == '':\n",
    "        pred_batch = torch.where((pred > thresh2)[0])[0].detach().tolist()\n",
    "        pred_batch = \",\".join([str(i) for i in pred_batch])\n",
    "        if pred_batch == '':\n",
    "            pred_batch = torch.where((pred > thresh3)[0])[0].detach().tolist()\n",
    "            pred_batch = \",\".join([str(i) for i in pred_batch])\n",
    "            if pred_batch == '':\n",
    "                print(pred)\n",
    "                pred_batch = \"0\"\n",
    "    submit.append(pred_batch)\n",
    "    \n",
    "sample_submission[\"target\"] = submit\n",
    "sample_submission.to_csv(\"data/submissions/submission_lstm_with_attention.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186bf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b2292c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d3cfaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
